GraphRAG permite comprender y navegar las relaciones entre entidades, proporcionando respuestas m√°s contextuales y explicables.

Permite identificar conexiones entre entidades, como entender que "el asesino era el mayordomo" debido a su relaci√≥n con la v√≠ctima.
Facilita saltar entre ideas relacionadas, incluso si no comparten las mismas palabras.
Ademas el grafo muestra todas las conexiones, ayudando a verificar la veracidad de las respuestas.

‚úÖ
Integraci√≥n de PDFs: documentos como tesis_n6208_Klappenbach e Inteligencia_Lavandera_LeccMag_USPCEU_2024
Se implement√≥ una interfaz que permite visualizar las conexiones entre entidades, facilitando la comprensi√≥n de las respuestas generadas.

üß© Desaf√≠os enfrentados
1. Embeddings inconsistentes
Intent√© usar OpenAI para los embeddings, pero al no ser los mismos que los del builder original, me daba respuestas que no ten√≠an nada que ver. Termin√© usando sentence-transformers que, aunque m√°s lento, al menos daba resultados consistentes.
Nodos fantasma: Muchos nodos ven√≠an con valores nulos o vac√≠os, y mi c√≥digo se romp√≠a de formas misteriosas.

‚òï Mejoras futuras
Refinamiento de relaciones: Mejorar la precisi√≥n en la identificaci√≥n de relaciones entre entidades para aprovechar al m√°ximo la estructura del grafo..

Integraci√≥n con LangChain y LangGraph: Estos frameworks ofrecen componentes preconstruidos que podr√≠an simplificar la gesti√≥n del contexto y las consultas, adem√°s de permitir flujos de trabajo m√°s complejos y din√°micos.

Ajuste din√°mico de embeddings: Implementar mecanismos que ajusten autom√°ticamente los par√°metros de b√∫squeda o cambien el modelo de embeddings seg√∫n el tipo de pregunta ademas de usar los mas actualizados..

Memoria dinamica: Permitir que el sistema recuerde interacciones anteriores para mantener conversaciones m√°s naturales y coherentes.

Funci√≥n de simplificaci√≥n: A√±adir un bot√≥n que simplifique las respuestas complejas y otro que permita profundizar en el tema seg√∫n el inter√©s del usuario.

üõ†Ô∏è Configuraci√≥n r√°pida para DevMode
Importante: Actualmente, el backend utiliza sentence-transformers para los embeddings, lo que requiere una cantidad significativa de memoria para ejecutarse en instancias gratuitas.., entonces localmente es la solucion en esta instancia.

Requisitos
Tener Docker instalado.

Pasos
Clonar la rama DevMode del repositorio.

Crear un archivo .env con las siguientes variables:

env
Copiar
Editar
NEO4J_URI=neo4j+s://tu-instancia.databases.neo4j.io
NEO4J_USER=neo4j
NEO4J_PASSWORD=xe5Y63flhQPBuBiwYebAis3FvrC_Tyt5peIZgy7DdGI
OPENAI_API_KEY=sk-tu-api-key
VECTOR_INDEX_NAME=vector
Construir la imagen de Docker:

bash
Copiar
Editar
docker-compose build
Iniciar los servicios:

bash
Copiar
Editar
docker-compose up
Acceder a la aplicaci√≥n en http://localhost:5000.

Abrir el archivo index.html para visualizar el grafo y las conexiones.


![image](https://github.com/user-attachments/assets/bdeea60e-26d3-4fd9-b3b7-5c093c024c24)
![image](https://github.com/user-attachments/assets/92a3fc52-1232-4c27-a279-d9ef6895e19a)

