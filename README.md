üöÄ ¬øPor qu√© GraphRAG?
GraphRAG va m√°s all√° de la simple recuperaci√≥n de informaci√≥n. Mientras que un sistema RAG tradicional busca coincidencias de palabras clave, GraphRAG permite comprender y navegar las relaciones entre entidades, proporcionando respuestas m√°s contextuales y explicables.

Permite identificar conexiones entre entidades, como entender que "el asesino era el mayordomo" debido a su relaci√≥n con la v√≠ctima.

Facilita saltar entre ideas relacionadas, incluso si no comparten las mismas palabras.

El grafo muestra todas las conexiones, ayudando a verificar la veracidad de las respuestas.

‚úÖ
Integraci√≥n de PDFs: Se logr√≥ procesar documentos como tesis_n6208_Klappenbach e Inteligencia_Lavandera_LeccMag_USPCEU_2024, extrayendo informaci√≥n relevante de estos 2 papers que hablan de IA (tecnologia) y neurociencia de la dopamina

Se implement√≥ una interfaz que permite visualizar las conexiones entre entidades, facilitando la comprensi√≥n de las respuestas generadas.

üß© Desaf√≠os
Inicialmente se utilizaron embeddings de OpenAI, pero al no coincidir con los del builder original "graphRAG builder neo4j", las respuestas eran incoherentes. Se opt√≥ por sentence-transformers, que, aunque m√°s lentos, ofrecieron resultados consistentes y eran los mismos generados por la interfaz.

Se encontraron nodos con valores nulos o vac√≠os, lo que causaba errores en el c√≥digo. Se implementaron validaciones para manejar estos casos y asegurar la estabilidad del sistema.

‚òï Mejoras futuras
Refinamiento de relaciones: Mejorar la precisi√≥n en la identificaci√≥n de relaciones entre entidades para aprovechar al m√°ximo la estructura del grafo.

Integraci√≥n con LangChain y LangGraph: Estos frameworks ofrecen componentes preconstruidos que podr√≠an simplificar la gesti√≥n del contexto y las consultas, adem√°s de permitir flujos de trabajo m√°s complejos y din√°micos.

Ajuste din√°mico de embeddings: Implementar mecanismos que ajusten autom√°ticamente los par√°metros de b√∫squeda o cambien el modelo de embeddings seg√∫n el tipo de pregunta.

Memoria de m√∫ltiples turnos: Permitir que el sistema recuerde interacciones anteriores para mantener conversaciones m√°s naturales y coherentes.

Funci√≥n de simplificaci√≥n: A√±adir un bot√≥n que simplifique las respuestas complejas y otro que permita profundizar en el tema seg√∫n el inter√©s del usuario.

üõ†Ô∏è Configuraci√≥n r√°pida para DevMode
Importante: Actualmente, el backend utiliza sentence-transformers para los embeddings, lo que requiere una cantidad significativa de memoria para ejecutarse localmente.

Requisitos
Tener Docker instalado.

Pasos
Clonar la rama DevMode del repositorio.

Crear un archivo .env con las siguientes variables:

env
Copiar
Editar
NEO4J_URI=neo4j+s://tu-instancia.databases.neo4j.io
NEO4J_USER=neo4j
NEO4J_PASSWORD=xe5Y63flhQPBuBiwYebAis3FvrC_Tyt5peIZgy7DdGI
OPENAI_API_KEY=sk-tu-api-key-car√≠sima
VECTOR_INDEX_NAME=vector
Construir la imagen de Docker:

bash
Copiar
Editar
docker-compose build
Iniciar los servicios:

bash
Copiar
Editar
docker-compose up
Acceder a la aplicaci√≥n en http://localhost:5000.

Abrir el archivo index.html para visualizar el grafo y las conexiones.


![image](https://github.com/user-attachments/assets/5ab0ee76-4871-46b8-9ce3-6469d8d2c42d)

![image](https://github.com/user-attachments/assets/1c55fa4d-ee3d-42e2-8840-1b4bfed47930)

